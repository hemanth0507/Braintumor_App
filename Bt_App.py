# -*- coding: utf-8 -*-
"""App.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n1qMfhCwwWrJoNjGCFxgvQIEtjspwtKD
"""

!pip uninstall -y gradio pydantic googletrans httpcore
!pip install gradio==3.50.2 "pydantic<2.0" reportlab gtts
!pip install SpeechRecognition
!pip install gradio pandas scikit-learn¬†openpyx

import gradio as gr
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from gtts import gTTS
import tempfile
import os
import smtplib
from email.message import EmailMessage
import pandas as pd
import difflib
import speech_recognition as sr
from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode
import io
from PIL import Image
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from google.colab import files

from google.colab import drive
drive.mount('/content/drive')
model = load_model('/content/drive/MyDrive/brain_tumor_model/brain_tumor_ml.h5')

# ‚úÖ Set your sender email and app password
SENDER_EMAIL = input("Enter your Gmail: ")
SENDER_PASSWORD = input("Enter your App Password: ")

# ‚úÖ Webcam capture function (Colab only)
def capture_webcam_image():
    js = """
    async function takePhoto() {
        const div = document.createElement('div');
        const capture = document.createElement('button');
        capture.textContent = 'üì∏ Capture';
        div.appendChild(capture);

        const video = document.createElement('video');
        video.style.display = 'block';
        video.style.width = '300px';
        div.appendChild(video);
        document.body.appendChild(div);

        const stream = await navigator.mediaDevices.getUserMedia({video: true});
        video.srcObject = stream;
        await video.play();

        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

        await new Promise((resolve) => capture.onclick = resolve);

        const canvas = document.createElement('canvas');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        canvas.getContext('2d').drawImage(video, 0, 0);

        stream.getVideoTracks()[0].stop();
        div.remove();

        return canvas.toDataURL('image/jpeg');
    }
    takePhoto();
    """
    display(Javascript(js))
    data = eval_js("takePhoto()")
    binary = b64decode(data.split(',')[1])
    img = Image.open(io.BytesIO(binary))
    return img

# ‚úÖ Capture image manually before running Gradio
print("üì∏ Click below to capture patient's live photo:")
patient_img = capture_webcam_image()
patient_img_path = "/content/patient_live_photo.jpg"
patient_img.save(patient_img_path)
print("‚úÖ Live photo saved.")

# ‚úÖ PDF Generator
def generate_pdf(patient_name, diagnosis, brain_image_path, patient_photo_path=None):
    pdf_path = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf").name
    c = canvas.Canvas(pdf_path, pagesize=A4)
    c.setFont("Helvetica-Bold", 16)
    c.drawString(50, 800, "üß† Brain Tumor Diagnosis Report")
    c.setFont("Helvetica", 12)
    c.drawString(50, 770, f"Patient Name: {patient_name}")
    c.drawString(50, 750, f"Diagnosis: {diagnosis}")
    if diagnosis.strip() == "Tumor Detected":
      c.setFillColorRGB(1, 0, 0)
      c.drawString(50, 730, "‚ö†Ô∏è Medical Advice:")
      c.setFillColorRGB(0, 0, 0)
      c.drawString(70, 715, "- Consult a neurologist immediately.")
      c.drawString(70, 700, "- MRI and Biopsy recommended.")
    else:
      c.setFillColorRGB(0, 0.5, 0)
      c.drawString(50, 730, "‚úÖ Advice:")
      c.setFillColorRGB(0, 0, 0)
      c.drawString(70, 715, "- No tumor detected. Stay healthy.")


    c.drawString(50, 670, "üñºÔ∏è Brain MRI Scan:")
    c.drawImage(brain_image_path, 50, 470, width=200, height=200)

    if patient_photo_path:
        c.drawString(300, 670, "üßë Patient Photo:")
        c.drawImage(patient_photo_path, 300, 470, width=150, height=200)

    c.save()
    return pdf_path

# ‚úÖ Send email with attachment
def send_email(recipient_email, subject, body, attachment_path):
    msg = EmailMessage()
    msg['Subject'] = subject
    msg['From'] = SENDER_EMAIL
    msg['To'] = recipient_email
    msg.set_content(body)

    with open(attachment_path, 'rb') as f:
        msg.add_attachment(f.read(), maintype='application', subtype='pdf', filename='BrainTumorReport.pdf')

    with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:
        smtp.login(SENDER_EMAIL, SENDER_PASSWORD)
        smtp.send_message(msg)

# ‚úÖ Tumor Prediction
def predict(image_input, patient_name, recipient_email, uploaded_photo):
    img = image_input.resize((224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0) / 255.0
    prediction = model.predict(img_array)[0][0]
    result = "Tumor Detected" if prediction > 0.5 else "No Tumor Detected"

    with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp_img:
        image_input.save(tmp_img.name)
        brain_img_path = tmp_img.name

    if uploaded_photo is not None:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp_face:
            uploaded_photo.save(tmp_face.name)
            patient_img_path = tmp_face.name
    else:
        patient_img_path = "/content/patient_live_photo.jpg"

    pdf_file = generate_pdf(patient_name, result, brain_img_path, patient_img_path)

    try:
        send_email(recipient_email, "Brain Tumor Report", f"Hi {patient_name}, your result is: {result}.", pdf_file)
        email_status = f"‚úÖ PDF report sent to {recipient_email}."
    except Exception as e:
        email_status = f"‚ùå Email failed: {str(e)}"

    return result, email_status, pdf_file

# ‚úÖ Brain Tumor Chatbot
qa_file_path = "/content/drive/MyDrive/brain_tumor_qa.csv"
history_log = []

def english_chatbot(text_input, audio_input):
    lang_code = "en"
    if audio_input is not None:
        recognizer = sr.Recognizer()
        with sr.AudioFile(audio_input) as source:
            recorded = recognizer.record(source)
        try:
            user_question = recognizer.recognize_google(recorded, language=lang_code)
        except:
            return "Sorry, couldn't understand your voice.", None, history_log
    else:
        user_question = text_input

    df = pd.read_csv(qa_file_path)
    questions = df["Question"].tolist()
    match = difflib.get_close_matches(user_question, questions, n=1, cutoff=0.4)
    if match:
        answer = df[df["Question"] == match[0]]['Answer'].values[0]
    else:
        answer = "Sorry, I couldn't find the answer."

    history_log.append(f"üë§ {user_question}\nü§ñ {answer}")

    tts = gTTS(answer, lang=lang_code)
    audio_reply = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3").name
    tts.save(audio_reply)
    return answer, audio_reply, "\n\n".join(history_log)

# ‚úÖ Fast load from Drive (no blocking)
suggestion_df = pd.read_excel("/content/suggestion.xlsx")
suggestion_df['Questions'] = suggestion_df['Questions'].str.lower()

# ‚úÖ Fit once and reuse
vectorizer = TfidfVectorizer()
question_vectors = vectorizer.fit_transform(suggestion_df['Questions'])

def get_suggestion(user_input):
    if not user_input.strip():
        return "Please ask a valid question related to brain tumour."
    user_input = user_input.lower()
    user_vector = vectorizer.transform([user_input])
    similarity = cosine_similarity(user_vector, question_vectors)
    best_match_index = similarity.argmax()
    best_score = similarity[0, best_match_index]
    if best_score < 0.2:
        return "Sorry, I couldn't find a suitable suggestion. Try rephrasing your question."
    return suggestion_df['Answers'].iloc[best_match_index]

# ‚úÖ Interfaces
image_input = gr.Image(type="pil", label="Upload MRI")
name_input = gr.Textbox(label="Patient Name")
email_input = gr.Textbox(label="Recipient Email")
photo_input = gr.Image(type="pil", label="üì∏ Upload Patient Photo (Optional)")
result_text = gr.Textbox(label="Diagnosis")
email_status = gr.Textbox(label="Email Status")
pdf_file = gr.File(label="Download PDF Report")

detect_interface = gr.Interface(
    fn=predict,
    inputs=[image_input, name_input, email_input, photo_input],
    outputs=[result_text, email_status, pdf_file],
    title="üß† Brain Tumor Detection",
    description="Upload MRI + patient photo (optional). PDF emailed with advice.",
    allow_flagging="never"
)

chat_interface = gr.Interface(
    fn=english_chatbot,
    inputs=[gr.Textbox(placeholder="Type your question"), gr.Audio(source="microphone", type="filepath")],
    outputs=[gr.Textbox(label="Bot Reply"), gr.Audio(), gr.Textbox(label="History")],
    title="üó£Ô∏è Brain Tumor Chatbot",
    description="Ask questions about brain tumors."
)

suggestion_interface = gr.Interface(
    fn=get_suggestion,
    inputs=gr.Textbox(label="Ask about Hospitals / Scan Centers"),
    outputs=gr.Textbox(label="Suggestion"),
    title="üè• Brain Tumor Treatment Suggestion Bot",
    description="Ask where to get treatment, scan centers, hospitals, etc.",
    examples=[
        "Best hospital for brain tumour scan center in Tamil Nadu?",
        "Which scan center is cheap for brain tumor treatment in Virudhunagar?",
        "Which is the best hospital to treat for brain tumor in Vellore?",
        "Which is the costliest hospital for brain tumor treatment in India?",
        "Which hospital is cheap for brain tumor treatment in Kancheepuram?"
    ],
    allow_flagging="never"
)

# ‚úÖ Final UI
app = gr.TabbedInterface([
    detect_interface,
    chat_interface,
    suggestion_interface
], ["Tumor Detector", "Chat Assistant", "Treatment Suggestion"])

app.launch(share=True)

